{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05079a74",
   "metadata": {},
   "source": [
    "### Quickstart: Compare runs, choose a model, and deploy it to a REST API\n",
    "\n",
    "In this notebook\n",
    "- Run a hyperparameter sweep on a training script\n",
    "- Compare the results of the runs in Mlflow ui\n",
    "- Choose the best run and register it as a model\n",
    "- Deploy the model to a REST API\n",
    "- Build a container image suitable for deployment to a cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae084956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.2.7)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (1.11.2)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (3.4.2)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (1.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (4.67.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (3.1.1)\n",
      "Requirement already satisfied: py4j in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from hyperopt) (0.10.9.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->hyperopt) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\hp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88c0c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Hyperopt is used for hyperparameter tuning for Deep Learning models.\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "069856b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load the dataset\n",
    "data=pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e209c42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4665</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.20</td>\n",
       "      <td>0.028</td>\n",
       "      <td>44.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99272</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.44</td>\n",
       "      <td>11.60</td>\n",
       "      <td>0.041</td>\n",
       "      <td>48.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.037</td>\n",
       "      <td>25.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.99268</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.49</td>\n",
       "      <td>11.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.036</td>\n",
       "      <td>33.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.99315</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.26</td>\n",
       "      <td>18.95</td>\n",
       "      <td>0.053</td>\n",
       "      <td>36.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3918 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4665            7.3              0.17         0.36            8.20      0.028   \n",
       "1943            6.3              0.25         0.44           11.60      0.041   \n",
       "3399            5.6              0.32         0.33            7.40      0.037   \n",
       "843             6.9              0.19         0.35            1.70      0.036   \n",
       "2580            7.7              0.30         0.26           18.95      0.053   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4665                 44.0                 111.0  0.99272  3.14       0.41   \n",
       "1943                 48.0                 195.0  0.99680  3.18       0.52   \n",
       "3399                 25.0                  95.0  0.99268  3.25       0.49   \n",
       "843                  33.0                 101.0  0.99315  3.21       0.54   \n",
       "2580                 36.0                 174.0  0.99976  3.20       0.50   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "4665     12.4        6  \n",
       "1943      9.5        5  \n",
       "3399     11.1        6  \n",
       "843      10.8        7  \n",
       "2580     10.4        5  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[3918 rows x 12 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training, validation and test sets\n",
    "train,test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ebc4297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop(\"quality\", axis=1).values\n",
    "# .ravel is used to convert the DataFrame to a 1D array\n",
    "train_y = train[\"quality\"].values.ravel()\n",
    "\n",
    "# Validation dataset \n",
    "test_x = test.drop(\"quality\", axis=1).values\n",
    "test_y = test[\"quality\"].values.ravel()\n",
    "\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "train_X,valid_X,train_y,valid_y = train_test_split(\n",
    "    train_X, train_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "signature = infer_signature(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fdf4b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN model\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "def train_model(params,epochs,train_X,train_y,valid_X,valid_y,test_x,test_y):\n",
    "    \n",
    "    # Define the model architecture\n",
    "    mean = np.mean(train_X,axis=0)\n",
    "    var = np.var(train_X,axis=0)\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "        keras.Input([train_X.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean, variance=var),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer = keras.optimizers.SGD(\n",
    "        learning_rate =params['lr'],\n",
    "        momentum = params['momentum'],\n",
    "    ),\n",
    "    loss = \"mean_squared_error\",\n",
    "    metrics = [keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    # Train the model\n",
    "    \n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_X,train_y,validation_data=(valid_X,valid_y),\n",
    "                epochs = epochs,\n",
    "                batch_size= 64)\n",
    "        \n",
    "        # Evaluate the model on the test set\n",
    "        eval_result = model.evaluate(valid_X,valid_y, batch_size=64)\n",
    "        \n",
    "        eval_rmse = eval_result[1]\n",
    "        \n",
    "        # log the parameter and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\", eval_rmse)\n",
    "        \n",
    "        # log the model\n",
    "        mlflow.tensorflow.log_model(model,\"model\",\n",
    "                                signature=signature,\n",
    "                                )\n",
    "        \n",
    "        return {\n",
    "            \"loss\": eval_rmse,\n",
    "            \"status\": STATUS_OK,\n",
    "            \"model\": model,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1a383289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results of each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_X=train_X,\n",
    "        train_y=train_y,\n",
    "        valid_X=valid_X,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "03c7675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\" : hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\", 0.0, 0.9),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9738c03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 330ms/step - loss: 35.6130 - root_mean_squared_error: 5.9677\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7524 - root_mean_squared_error: 4.6009   \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 21.5673 - root_mean_squared_error: 4.5796 - val_loss: 3.2817 - val_root_mean_squared_error: 1.8116\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 3.1878 - root_mean_squared_error: 1.7854\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4911 - root_mean_squared_error: 1.5770 - val_loss: 2.2289 - val_root_mean_squared_error: 1.4929\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 1.9977 - root_mean_squared_error: 1.4134\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7310 - root_mean_squared_error: 1.3154 - val_loss: 1.8495 - val_root_mean_squared_error: 1.3599\n",
      "\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.6288 - root_mean_squared_error: 1.2762\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7240 - root_mean_squared_error: 1.3113 \n",
      "\n",
      "Epoch 1/3                                                                       \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 367ms/step - loss: 32.9343 - root_mean_squared_error: 5.7388\n",
      "\u001b[1m29/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0867 - root_mean_squared_error: 2.4973    \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 5.0606 - root_mean_squared_error: 2.0793 - val_loss: 0.6060 - val_root_mean_squared_error: 0.7784\n",
      "\n",
      "Epoch 2/3                                                                       \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.8669 - root_mean_squared_error: 0.9311\n",
      "\u001b[1m20/49\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7246 - root_mean_squared_error: 0.8509 \n",
      "\u001b[1m44/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6692 - root_mean_squared_error: 0.8172\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6615 - root_mean_squared_error: 0.8125 - val_loss: 0.4956 - val_root_mean_squared_error: 0.7040\n",
      "\n",
      "Epoch 3/3                                                                       \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.5616 - root_mean_squared_error: 0.7494\n",
      "\u001b[1m36/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5530 - root_mean_squared_error: 0.7436 \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5525 - root_mean_squared_error: 0.7432 - val_loss: 0.5423 - val_root_mean_squared_error: 0.7364\n",
      "\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5447 - root_mean_squared_error: 0.7380\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5185 - root_mean_squared_error: 0.7200 \n",
      "\n",
      "Epoch 1/3                                                                       \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 317ms/step - loss: 31.9190 - root_mean_squared_error: 5.6497\n",
      "\u001b[1m41/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.7384 - root_mean_squared_error: 5.2581   \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 26.6375 - root_mean_squared_error: 5.1486 - val_loss: 12.0129 - val_root_mean_squared_error: 3.4660\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 12.2352 - root_mean_squared_error: 3.4979\n",
      "\u001b[1m27/49\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3975 - root_mean_squared_error: 3.2215 \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.3193 - root_mean_squared_error: 3.0445 - val_loss: 4.8868 - val_root_mean_squared_error: 2.2106\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 5.2893 - root_mean_squared_error: 2.2998\n",
      "\u001b[1m35/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9779 - root_mean_squared_error: 1.9909 \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.7760 - root_mean_squared_error: 1.9390 - val_loss: 3.1335 - val_root_mean_squared_error: 1.7702\n",
      "\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.8154 - root_mean_squared_error: 1.6779\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.0266 - root_mean_squared_error: 1.7379 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 312ms/step - loss: 40.5550 - root_mean_squared_error: 6.3683\n",
      "\u001b[1m37/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.9205 - root_mean_squared_error: 6.2382   \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 38.5727 - root_mean_squared_error: 6.2102 - val_loss: 34.9078 - val_root_mean_squared_error: 5.9083\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 33.1503 - root_mean_squared_error: 5.7576\n",
      "\u001b[1m47/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 33.6932 - root_mean_squared_error: 5.8042 \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.6179 - root_mean_squared_error: 5.7977 - val_loss: 30.3024 - val_root_mean_squared_error: 5.5048\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/49\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 31.4366 - root_mean_squared_error: 5.6068\n",
      "\u001b[1m31/49\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.3696 - root_mean_squared_error: 5.4191 \n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.0215 - root_mean_squared_error: 5.3868 - val_loss: 26.3357 - val_root_mean_squared_error: 5.1318\n",
      "\n",
      "\u001b[1m 1/13\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26.3709 - root_mean_squared_error: 5.1353\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 26.4066 - root_mean_squared_error: 5.1387 \n",
      "\n",
      "100%|██████████| 4/4 [02:29<00:00, 37.35s/trial, best loss: 0.7364414930343628]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 03:44:01 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 03:44:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr': 0.09240564863599812, 'momentum': 0.5340682838337641}\n",
      "Best eval rmse: 0.7364414930343628\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\")  # signature removed\n",
    "\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aee0f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 03:53:23 INFO mlflow.models.python_api: It is highly recommended to use `uv` as the environment manager for predicting with MLflow models as its performance is significantly better than other environment managers. Run `pip install uv` to install uv. See https://docs.astral.sh/uv/getting-started/installation for other installation methods.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57464a554d6e4a05b7000962887b9566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 03:53:23 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "{\"predictions\": [[6.4486565589904785], [6.676247596740723], [6.604545593261719], [5.843067646026611], [6.292703628540039], [6.74277400970459], [5.890346050262451], [5.409409523010254], [6.071342468261719], [5.792107582092285], [6.638113975524902], [4.828298568725586], [6.895570755004883], [5.53580379486084], [7.446080684661865], [5.8251261711120605], [6.762073993682861], [6.278621673583984], [6.13313102722168], [5.825350761413574], [5.884515762329102], [6.194972038269043], [5.605582237243652], [6.581955432891846], [6.2860260009765625], [5.7660017013549805], [5.5777459144592285], [6.299234867095947], [6.270047187805176], [5.498980522155762], [5.840116500854492], [6.021317958831787], [5.877445220947266], [5.767542362213135], [5.934970378875732], [6.5357441902160645], [6.484499454498291], [5.349887371063232], [5.997633457183838], [6.0958967208862305], [6.125141620635986], [5.791303634643555], [6.018287658691406], [5.824871063232422], [5.295968055725098], [5.930450916290283], [6.391044616699219], [5.604631423950195], [5.929194450378418], [5.946184158325195], [5.114378929138184], [6.161426544189453], [6.238113880157471], [6.3530473709106445], [6.358166694641113], [5.922209739685059], [6.054845333099365], [5.867074966430664], [5.895803451538086], [6.450408935546875], [6.250578880310059], [6.360645294189453], [5.33712911605835], [7.007632255554199], [6.185061454772949], [6.4730424880981445], [6.489496231079102], [6.135379314422607], [6.401690483093262], [6.043701171875], [5.119653701782227], [6.262962818145752], [4.695126056671143], [4.575045585632324], [5.918298244476318], [6.914201736450195], [6.03781795501709], [6.050532817840576], [7.092289924621582], [6.511171340942383], [6.283994674682617], [5.7123212814331055], [6.120997428894043], [5.702057838439941], [6.384519577026367], [6.467144966125488], [5.671858787536621], [5.964571475982666], [7.039792537689209], [6.273046016693115], [6.654757499694824], [5.383136749267578], [5.824617385864258], [6.772755146026611], [6.808282852172852], [6.671769142150879], [6.7297773361206055], [6.157257080078125], [5.460254669189453], [7.065217018127441], [5.825070381164551], [6.104895114898682], [6.614206790924072], [6.1871657371521], [6.022525787353516], [6.5423383712768555], [6.450408935546875], [6.46757173538208], [6.278621673583984], [6.197695732116699], [5.952144622802734], [5.858236312866211], [6.690537452697754], [6.296097755432129], [5.890268802642822], [6.973540306091309], [6.822274208068848], [6.466594696044922], [5.666475296020508], [6.881851673126221], [5.841036319732666], [6.96914005279541], [6.401262283325195], [5.634346961975098], [6.309933662414551], [6.353153228759766], [6.999460220336914], [5.798833847045898], [6.576022148132324], [5.786892890930176], [5.951964378356934], [6.377192974090576], [5.592838287353516], [6.316360950469971], [5.33237361907959], [6.5661516189575195], [6.291280269622803], [5.759287357330322], [6.467456817626953], [5.816775321960449], [6.757645130157471], [6.131760597229004], [5.985617160797119], [5.998761177062988], [6.410996437072754], [5.739725112915039], [5.430839538574219], [5.810503959655762], [5.706505298614502], [5.866363525390625], [6.470266342163086], [5.807575225830078], [6.2664690017700195], [6.335325717926025], [6.311819076538086], [5.201450347900391], [6.6141767501831055], [6.18843936920166], [6.176175594329834], [6.585082054138184], [5.6325364112854], [5.614413738250732], [6.638653755187988], [6.2128167152404785], [6.450327396392822], [6.675301551818848], [5.055599212646484], [5.981817245483398], [5.811248779296875], [6.246342182159424], [5.307482719421387], [6.237847328186035], [6.3076629638671875], [6.012998580932617], [7.003312587738037], [5.871293067932129], [5.788417816162109], [6.394528388977051], [6.21415376663208], [5.498347282409668], [6.607640266418457], [6.04109001159668], [5.641883850097656], [6.196805477142334], [5.638521194458008], [5.647460460662842], [6.264169216156006], [5.986856937408447], [6.105923175811768], [5.800109386444092], [5.877895355224609], [5.717514991760254], [6.233717441558838], [6.63353967666626], [5.266178131103516], [5.819256782531738], [6.887851715087891], [6.6693878173828125], [5.866024017333984], [5.974881172180176], [6.557916641235352], [4.689979553222656], [6.635124683380127], [6.123478889465332], [5.701125621795654], [6.091629505157471], [6.815277099609375], [6.3876261711120605], [5.668766975402832], [6.1710052490234375], [6.406012535095215], [6.319362640380859], [6.643809795379639], [6.474361896514893], [4.715035438537598], [6.014922142028809], [5.896793842315674], [5.464301109313965], [6.360645294189453], [6.654973030090332], [6.1644792556762695], [6.155876636505127], [5.898290634155273], [6.497325420379639], [6.367861747741699], [5.551764965057373], [6.25919246673584], [6.933823585510254], [6.320855140686035], [5.561563491821289], [5.84419059753418], [5.777351379394531], [6.321004390716553], [5.857989311218262], [5.900198936462402], [7.090738773345947], [6.194333076477051], [6.514292240142822], [6.390072822570801], [5.716788291931152], [5.905099868774414], [5.088688850402832], [6.816549301147461], [6.154301643371582], [6.047593593597412], [5.1288323402404785], [5.713354587554932], [5.422002792358398], [6.156084060668945], [5.2023210525512695], [6.309151649475098], [5.570888519287109], [5.696172714233398], [5.606058597564697], [5.870965957641602], [5.748092174530029], [6.13525390625], [6.109671592712402], [5.775745391845703], [6.081385612487793], [5.867860317230225], [5.37156867980957], [5.389063358306885], [5.044323444366455], [6.754043102264404], [6.178230285644531], [5.735719680786133], [6.022501468658447], [6.134185791015625], [5.948596954345703], [5.541143417358398], [6.177175521850586], [6.463700294494629], [6.901242256164551], [5.568633556365967], [6.55199670791626], [5.7399091720581055], [6.058474063873291], [6.626767158508301], [6.0747456550598145], [5.877979278564453], [5.918298244476318], [6.232849597930908], [5.441632270812988], [6.682125091552734], [6.763607025146484], [7.340339183807373], [5.917277812957764], [5.877575874328613], [5.683090686798096], [5.900297164916992], [5.887158393859863], [6.472357273101807], [6.110608100891113], [6.509579658508301], [6.339485168457031], [5.8609395027160645], [6.035774230957031], [5.493098258972168], [5.998140335083008], [5.114378929138184], [5.825789451599121], [6.740607261657715], [5.3986287117004395], [6.687628269195557], [5.892298698425293], [6.0804829597473145], [6.03723669052124], [6.555714130401611], [5.618826866149902], [6.045294761657715], [6.584214210510254], [5.656225681304932], [6.384091854095459], [5.7969865798950195], [7.334380626678467], [6.049895286560059], [6.445304870605469], [5.133460998535156], [6.539170742034912], [6.470010280609131], [6.800071716308594], [6.401308059692383], [6.364475250244141], [5.442061424255371], [5.528589725494385], [7.006590843200684], [5.898029327392578], [7.069223403930664], [6.222805976867676], [6.103471279144287], [6.517871856689453], [7.2406134605407715], [6.247501850128174], [5.4612274169921875], [6.080057144165039], [6.7991557121276855], [6.685986042022705], [6.155926704406738], [6.207413673400879], [5.859752178192139], [6.341175556182861], [5.728676795959473], [6.42561149597168], [5.74252986907959], [5.776851654052734], [6.445746421813965], [5.352349281311035], [7.101386547088623], [6.536466598510742], [6.844755172729492], [6.6671648025512695], [6.022525787353516], [5.785078048706055], [6.560353755950928], [5.606058597564697], [5.9955949783325195], [6.263510704040527], [6.766796112060547], [5.66901969909668], [5.563139915466309], [5.625887393951416], [5.868528366088867], [6.135826587677002], [6.0172929763793945], [5.483693599700928], [5.887566566467285], [5.861919403076172], [6.043497085571289], [6.409397125244141], [5.403800964355469], [5.876014709472656], [6.079854965209961], [6.389814376831055], [6.512171745300293], [6.016590118408203], [6.3604207038879395], [5.58480978012085], [6.648619651794434], [5.988251686096191], [6.668946743011475], [6.2115983963012695], [6.556679725646973], [6.070856094360352], [6.170753002166748], [6.292332649230957], [6.395596981048584], [5.969606876373291], [6.523351669311523], [5.659084320068359], [5.366933345794678], [6.150674343109131], [5.917219638824463], [6.072122097015381], [4.987467288970947], [5.9821624755859375], [4.680150985717773], [6.349813461303711], [6.525330066680908], [6.113590240478516], [4.865500450134277], [6.218884468078613], [6.182833194732666], [6.345973491668701], [5.938858509063721], [6.27629280090332], [6.4154462814331055], [5.690317153930664], [6.517849445343018], [7.0003886222839355], [6.110608100891113], [5.836768627166748], [7.022871971130371], [5.869650840759277], [6.086470603942871], [6.346250057220459], [5.027232646942139], [6.234647750854492], [4.544167995452881], [6.301619529724121], [6.319745063781738], [6.050623893737793], [6.314131259918213], [6.344733238220215], [6.807554244995117], [6.119704246520996], [6.101709842681885], [6.602919578552246], [6.580182075500488], [6.0647172927856445], [6.305712699890137], [5.742158889770508], [5.602210998535156], [6.171093940734863], [6.448875427246094], [5.70289421081543], [6.769244194030762], [6.631518363952637], [5.405707359313965], [6.345113754272461], [6.235009670257568], [7.040753364562988], [6.914201736450195], [5.613121032714844], [5.959205627441406], [6.444771766662598], [6.833832740783691], [6.12995719909668], [5.324887275695801], [6.158463954925537], [5.560598373413086], [6.212258338928223], [5.859847068786621], [6.755302429199219], [6.365801811218262], [6.128243446350098], [5.281352996826172], [6.575910568237305], [4.887988090515137], [5.444316864013672], [5.910496711730957], [6.581910610198975], [6.043996334075928], [5.774847984313965], [6.404475212097168], [6.735905647277832], [6.08557653427124], [5.976125717163086], [6.683241844177246], [4.962276935577393], [5.502403736114502], [6.392865180969238], [6.3127121925354], [5.727283954620361], [4.713586330413818], [6.082634925842285], [5.895063400268555], [5.908256530761719], [6.285367965698242], [6.551360607147217], [6.097023963928223], [5.200198173522949], [5.595943450927734], [5.771087169647217], [5.144148826599121], [6.806520462036133], [6.448077201843262], [5.836548805236816], [5.883979797363281], [5.6569318771362305], [5.737307548522949], [5.557843208312988], [6.499721527099609], [6.3731184005737305], [6.472622394561768], [6.733924865722656], [6.048088550567627], [5.748092174530029], [6.061357498168945], [5.158802032470703], [6.328786373138428], [5.958064079284668], [6.064687728881836], [6.539933204650879], [6.020576477050781], [5.811352729797363], [6.5796098709106445], [6.123415470123291], [6.241137504577637], [6.567813873291016], [6.402649879455566], [5.131031513214111], [5.711195468902588], [6.161698818206787], [6.190398216247559], [6.111043930053711], [5.973133087158203], [5.784319877624512], [5.723348617553711], [5.016846656799316], [5.250573635101318], [5.053744316101074], [5.986785411834717], [6.029101371765137], [6.141765594482422], [6.021317958831787], [6.644426345825195], [6.320789337158203], [5.876422882080078], [4.888108253479004], [6.764222145080566], [6.220200538635254], [5.671858787536621], [5.587259292602539], [6.18991231918335], [5.814251899719238], [6.279314994812012], [6.881245136260986], [6.689166069030762], [6.199240207672119], [5.558916091918945], [5.540462970733643], [6.929705619812012], [5.689807891845703], [6.831603050231934], [5.763028144836426], [6.383604049682617], [6.059981822967529], [5.849003791809082], [6.082363128662109], [6.2833380699157715], [6.6457061767578125], [6.440101623535156], [5.742090225219727], [7.003312587738037], [7.225759506225586], [7.139133453369141], [7.116734027862549], [5.755986213684082], [6.223945140838623], [7.1607136726379395], [6.196177959442139], [6.514310836791992], [5.692135810852051], [6.335909366607666], [5.673901557922363], [6.0482683181762695], [5.962939262390137], [6.448138236999512], [5.606799602508545], [6.106223106384277], [6.027469635009766], [6.158799171447754], [6.234947204589844], [6.291168212890625], [5.978867530822754], [6.166613578796387], [6.241137504577637], [6.5774641036987305], [6.370499610900879], [5.299523830413818], [6.687302589416504], [6.648965835571289], [5.614314556121826], [6.06279993057251], [5.692607879638672], [6.577692985534668], [5.722012519836426], [6.323909759521484], [6.202469348907471], [6.648619651794434], [6.363729476928711], [5.340736389160156], [6.94307279586792], [5.5371599197387695], [6.1901021003723145], [6.677530765533447], [6.623791694641113], [5.896940231323242], [5.746789932250977], [5.929194450378418], [6.416631698608398], [6.246306419372559], [5.895097255706787], [5.95085334777832], [7.050347328186035], [5.840728282928467], [6.232108116149902], [6.389814376831055], [6.4521331787109375], [6.353287220001221], [6.897711753845215], [6.258840084075928], [6.3615570068359375], [6.250403881072998], [5.567258834838867], [5.884329795837402], [6.327493190765381], [6.097764492034912], [5.870828628540039], [6.270047187805176], [6.5633649826049805], [5.545289993286133], [6.178353309631348], [6.202007293701172], [5.767110347747803], [6.800071716308594], [4.486642837524414], [5.433511734008789], [6.922889709472656], [5.317602157592773], [5.791303634643555], [6.587976455688477], [6.4563889503479], [5.855496406555176], [5.756955146789551], [6.118454933166504], [5.654427528381348], [5.961472511291504], [6.5088982582092285], [5.836091041564941], [6.707767009735107], [6.559741973876953], [5.001180648803711], [5.528646945953369], [5.526259422302246], [6.429889678955078], [5.692246437072754], [6.554660797119141], [6.477190017700195], [7.054087162017822], [6.595329761505127], [6.473663330078125], [6.317093849182129], [7.225759506225586], [6.082363128662109], [6.144580364227295], [5.119034767150879], [6.003495216369629], [5.744407653808594], [7.033204078674316], [6.621315002441406], [6.436486721038818], [6.581955432891846], [5.617666721343994], [6.505478382110596], [5.961428165435791], [5.400127410888672], [6.384966850280762], [5.913532257080078], [6.043593406677246], [6.4856672286987305], [5.585730075836182], [5.677867412567139], [6.614784240722656], [6.385751724243164], [5.688114166259766], [6.94307279586792], [5.683197975158691], [6.377462863922119], [6.030190944671631], [6.087414741516113], [6.477789878845215], [6.526729583740234], [6.156223297119141], [6.154696464538574], [6.082925796508789], [5.5168561935424805], [5.836619853973389], [6.36958646774292], [5.904180526733398], [5.816065788269043], [5.946184158325195], [6.923703193664551], [6.61886739730835], [7.033204078674316], [5.957150459289551], [5.908341884613037], [6.397435188293457], [5.452662944793701], [5.5229387283325195], [5.9163384437561035], [5.9195556640625], [6.627009391784668], [6.226506233215332], [5.918280124664307], [7.052529811859131], [6.771623611450195], [5.8358588218688965], [6.085947036743164], [5.446285724639893], [6.5443339347839355], [6.738103866577148], [6.567719459533691], [5.5733819007873535], [5.474886894226074], [5.878574371337891], [6.318046569824219], [5.888349533081055], [6.403244495391846], [5.319591522216797], [5.0882086753845215], [5.608487129211426], [6.386351108551025], [6.205449104309082], [5.875772953033447], [6.1843156814575195], [6.1579060554504395], [6.691208362579346], [5.716697692871094], [5.3053436279296875], [6.091629505157471], [6.81451416015625], [6.0215067863464355], [5.562643051147461], [5.5052995681762695], [6.357613563537598], [6.3278656005859375], [6.144498825073242], [7.143370628356934], [6.204999923706055], [5.307751655578613], [6.529888153076172], [6.358243942260742], [6.821194171905518], [6.1226654052734375], [6.45301628112793], [5.33425760269165], [6.586615562438965], [6.676552772521973], [5.831130027770996], [5.73892068862915], [6.898923873901367], [7.093644142150879], [5.766307353973389], [5.396573066711426], [6.335325717926025], [6.0205793380737305], [5.563431739807129], [6.052486419677734], [6.107822418212891], [6.117953777313232], [5.986432075500488], [6.4662675857543945], [6.412463665008545], [6.656768798828125], [5.801398277282715], [6.2659454345703125], [6.117002964019775], [5.826770305633545], [5.697912216186523], [6.635451316833496], [5.715419769287109], [6.217252254486084], [5.697920799255371], [7.1607136726379395], [6.664397239685059], [6.372354984283447], [6.976117134094238], [6.099265098571777], [6.141920566558838], [6.394814968109131], [6.373488426208496], [5.763895034790039], [6.297041893005371], [6.363747596740723], [6.741754531860352], [5.820253849029541], [5.241302013397217], [6.259562969207764], [5.98604154586792], [6.724838733673096], [5.703774452209473], [6.126516342163086], [5.67739725112915], [6.678427696228027], [6.564119338989258], [6.248739719390869], [4.727662563323975], [5.923409461975098], [6.676271915435791], [6.131748199462891], [5.790164470672607], [5.623335838317871], [6.1771931648254395], [6.0804595947265625], [6.336935997009277], [5.752572536468506], [6.848618507385254], [6.04020357131958], [5.9584245681762695], [5.916916847229004], [5.902265548706055], [6.731152057647705], [5.953929424285889], [6.064112663269043], [6.230639457702637], [5.229713439941406], [5.713860511779785], [6.923381805419922], [6.526264190673828], [5.359908580780029], [6.415760040283203], [6.7340312004089355], [5.144057273864746], [5.902265548706055], [7.419046401977539], [5.465907096862793], [5.686840057373047], [6.06533670425415], [6.410996437072754], [5.725429534912109], [6.550415515899658], [6.4154462814331055], [6.540404796600342], [5.701703071594238], [6.3932623863220215], [5.791979789733887], [6.257126808166504], [5.994995594024658], [6.77956485748291], [6.412514686584473], [5.862148284912109], [6.689014434814453], [6.354443550109863], [6.0630645751953125], [6.116617679595947], [6.116790771484375], [5.7673845291137695], [6.161916732788086], [6.059938430786133], [6.328173637390137], [7.160799503326416], [6.295522689819336], [6.584437847137451], [6.192647933959961], [6.080656051635742], [6.539987564086914], [5.287949562072754], [6.204894542694092], [4.801904201507568], [5.715419769287109], [4.96495246887207], [6.612955570220947], [6.103239059448242], [6.970241546630859], [6.385569095611572], [6.457398891448975], [6.607174873352051], [5.9482951164245605], [5.788402080535889], [6.258312702178955], [6.99062442779541], [5.752572536468506], [5.637615203857422], [5.665040493011475], [6.642261981964111], [6.205366134643555], [6.647796630859375], [6.544266700744629], [5.949606895446777], [6.187873840332031], [6.832817554473877], [6.35322380065918], [6.174242973327637], [6.278296947479248], [6.210659980773926], [5.829355239868164], [5.560633182525635], [6.225820541381836], [5.646678447723389], [6.353028774261475], [6.3588056564331055], [5.983505725860596], [6.111043930053711], [6.703612804412842], [6.40146017074585], [6.096081733703613], [5.522735595703125], [6.49260950088501], [5.620923042297363], [6.372354984283447], [5.87769079208374], [5.754587173461914], [4.880053520202637], [5.974881172180176], [5.9954023361206055], [6.668180465698242], [6.285312652587891], [6.016590118408203], [6.035928726196289], [5.692220687866211], [6.176958084106445], [6.085058212280273], [6.5521721839904785], [6.327493190765381], [5.525213718414307], [6.340151786804199], [5.981371879577637], [6.473901748657227], [5.543600082397461], [6.126527786254883], [6.5154619216918945], [7.50118350982666], [6.894852638244629], [6.207902908325195], [7.151080131530762], [6.3250908851623535], [5.866024017333984], [5.619017601013184], [6.517012119293213], [6.18794059753418], [6.478803634643555], [5.1866655349731445], [5.772436141967773], [6.523061752319336], [5.280457973480225], [5.697920799255371], [6.607174873352051], [6.274748802185059], [5.867071151733398], [7.005038261413574], [6.37255334854126], [5.894186973571777], [5.9418182373046875], [5.4794206619262695], [5.876957416534424], [5.933721542358398], [6.36926794052124], [5.774397850036621], [5.669713020324707], [5.483667850494385], [5.935323715209961], [6.51425313949585], [6.6009039878845215], [6.65989875793457], [6.692480564117432], [6.293483734130859], [5.4124956130981445], [6.376577854156494], [7.028616905212402], [5.52133846282959], [6.608402252197266], [4.462604522705078], [5.987718105316162], [6.159857273101807], [6.211964130401611], [6.5566792488098145], [6.337427139282227], [5.065291881561279], [6.421244144439697], [5.81467342376709], [5.789689064025879], [5.381302833557129], [6.427296161651611], [6.04724645614624], [6.067244529724121], [5.885030746459961], [5.739129066467285], [5.984034061431885]]}"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_uri = 'runs:/4dd3db076e4e4ff48e5e7b2d075afdfb/model'\n",
    "\n",
    "# Replace INPUT_EXAMPLE with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "input_data = test_x\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"local\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3e6c7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.499022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.337129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.776067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.086769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.086769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.234409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>5.816775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>5.743985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>6.766796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.455517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     6.499022\n",
       "1     5.337129\n",
       "2     5.776067\n",
       "3     6.086769\n",
       "4     6.086769\n",
       "...        ...\n",
       "4893  6.234409\n",
       "4894  5.816775\n",
       "4895  5.743985\n",
       "4896  6.766796\n",
       "4897  6.455517\n",
       "\n",
       "[4898 rows x 1 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/4dd3db076e4e4ff48e5e7b2d075afdfb/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "# Only use feature columns for prediction\n",
    "feature_data = data.drop(\"quality\", axis=1)\n",
    "loaded_model.predict(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c8541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
